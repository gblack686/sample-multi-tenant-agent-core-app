# TAC Agentic Prompting Recipes
# Demonstrates the 4 abstraction layers: Command → Agent → Orchestrator → Just
#
# Based on patterns from: agentic-finance-review (SSVA pattern)
# "Focused Agent + Specialized Validation = Trusted Automation"

# ─── Layer 1: Commands (Logic) ─────────────────────────────

# Prime the session — load all project context before working
prime:
    claude "/prime"

# Run a single command directly
normalize csv_path:
    claude "/normalize-csv {{csv_path}}"

# Edit a CSV with instructions
csv-edit csv_path instructions:
    claude "/csv-edit {{csv_path}} {{instructions}}"

# Generate graphs from a data directory
graph-insights dir_path:
    claude "/graph-insights {{dir_path}}"

# Generate a dashboard from a data directory
generative-ui dir_path:
    claude "/generative-ui {{dir_path}}"

# ─── Layer 2: Agents (Isolation + Parallelism) ─────────────

# Run a single agent — isolated context, scoped hooks
run-agent agent_name prompt:
    claude "Use @{{agent_name}} to: {{prompt}}"

# Run the normalize agent on a directory (agent loops over files)
normalize-agent dir_path:
    claude "Use @normalize-csv-agent to normalize all CSVs in {{dir_path}}"

# Run the categorize agent on a file
categorize-agent csv_path:
    claude "Use @categorize-csv-agent to categorize {{csv_path}}"

# ─── Layer 3: Orchestrator (Sequential Pipeline) ──────────

# Full finance review — sequential pipeline with fail-fast gating
# normalize → categorize → merge → accumulate → graph → dashboard
review month *csv_files:
    claude "/review-finances {{month}} {{csv_files}}"

# ─── Layer 4: Just (Reusability + Composition) ────────────

# Full monthly review with default mock data
review-january:
    just review january mock-input-data/raw_checkings_jan.csv mock-input-data/raw_savings_jan.csv

review-february:
    just review february mock-input-data/raw_checkings_feb.csv mock-input-data/raw_savings_feb.csv

# Run all months sequentially
review-all:
    just review-january
    just review-february

# ─── Validation Recipes ───────────────────────────────────

# Run a specific validator manually (for debugging)
validate-csv dir_path:
    uv run .claude/hooks/validators/csv-validator.py < /dev/null

validate-html dir_path:
    uv run .claude/hooks/validators/html-validator.py < /dev/null

validate-graphs dir_path:
    uv run .claude/hooks/validators/graph-validator.py < /dev/null

# ─── Development ──────────────────────────────────────────

# Build with type-check + lint validation (hooks fire on Stop)
build prompt:
    claude "/build {{prompt}}"

# View the latest dashboard
view:
    claude "/view"

# ─── TAC Pattern Reference ───────────────────────────────
#
# This justfile demonstrates these TAC patterns:
#
# 1. SSVA (Specialized Self-Validating Agents)
#    Each agent has hooks scoped to its frontmatter, not global.
#    The validator fires per-operation (PostToolUse) or at completion (Stop).
#
# 2. Block/Retry = Autonomous Self-Correction
#    Hook output: {"decision": "block", "reason": "Missing column: date"}
#    The reason string becomes Claude's next correction task.
#
# 3. Agents for parallelism, Commands for logic
#    Commands hold the prompt. Agents invoke commands via Skill() and handle loops.
#
# 4. Fail-fast pipeline gating
#    Orchestrator runs agents sequentially. If one fails, pipeline stops.
#    Stop hooks enforce this mechanically.
#
# 5. CLAUDE.md as shared variable registry
#    ROOT_OPERATIONS_DIR defined once in CLAUDE.md, referenced everywhere.
#
# 6. uv run --script for portable validators
#    PEP 723 inline deps. Zero-install. Every validator is self-contained.
#
# 7. prime.md session initialization
#    Load all agents/commands/hooks at session start. One command = full context.
#
# 8. Two-tier tool restriction
#    Global allowlist in settings.json + per-command allowed-tools in frontmatter.
